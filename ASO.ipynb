{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NASAASO](Images/ASOInc_QuandaryPeak_web.jpg)\n",
    "\n",
    "# Retreiving, Processing, and Analyzing NASA Airborne Snow Observatory (ASO) SWE data product\n",
    "\n",
    "In this exercise, the user will programatically retreive, process, and spatio temporally analyze swe from NASA ASO missions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create Map for Watershed for USGS Station ID\n",
    "The following code uses the pynhd and folium packages to create an interactive map of a watershed from a USGS gauge ID.\n",
    "\n",
    "In our exercise, we are tasked with identifying all SNOTEL sites upstream of Hetch Hetchy Reservoir on the Tuolumne River. The user can search for \"USGS streamflow Tuolumne River\" and serveral locations will pop up. Site [11274790](https://waterdata.usgs.gov/monitoring-location/11274790/#dataTypeId=continuous-00065-0&period=P7D&showMedian=false) is the site of interest for this assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynhd import NLDI, WaterData, NHDPlusHR, GeoConnex\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from supporting_scripts import ASOget, dataprocessing, mapping, SSWEET, get_Elevation\n",
    "from shapely.geometry import box, Polygon\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the watershed outlet using NWIS site id. Create a map object that we'll add layers to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nldi = NLDI()\n",
    "usgs_gage_id = \"11274790\" # NWIS id for Tuolumne river at the mouth of Hetch Hetchy Reservoir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect watershed and reach vectors using the pynhd module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nldi = NLDI()\n",
    "\n",
    "#Getting basin geometry\n",
    "print('Collecting basins...', end='')\n",
    "basin = nldi.get_basins(usgs_gage_id)\n",
    "if not os.path.exists('files'):\n",
    "    os.makedirs('files')\n",
    "basin.to_file(\"files/TuolumneRiverBasin.shp\")\n",
    "print('done')\n",
    "\n",
    "site_feature = nldi.getfeature_byid(\"nwissite\", f\"USGS-{usgs_gage_id}\")\n",
    "upstream_network = nldi.navigate_byid(\n",
    "    \"nwissite\", f\"USGS-{usgs_gage_id}\", \"upstreamMain\", \"flowlines\", distance=9999\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and interactive map to display the watershed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "mapping.basin_mapping(basin, site_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Basin](Images/basin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Retrieve NASA ASO SWE data product for basin of interest\n",
    "\n",
    "note*, new users will have to [create a .netrc file](https://earthaccess.readthedocs.io/en/latest/howto/authenticate/):\n",
    "\n",
    "import earthaccess\n",
    "\n",
    "earthaccess.login(persist=True)\n",
    "\n",
    "*note, this script can time some time to process(~10 minutes), is prone to loosing html connection, and will grab any NASA ASO Image within the bounding box of your basin of interest, making the reproduction of this code tedious.\n",
    "\n",
    "In the spirit of the module, ee have QA/QC'd these for you, which we zip and include for you in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import earthaccess https://earthaccess.readthedocs.io/en/latest/howto/authenticate/\n",
    "# earthaccess.login(persist=True)\n",
    "\n",
    "# Inputs for fetching ASO data for a region\n",
    "short_name = 'ASO_50M_SWE'\n",
    "version = '1'\n",
    "time_start = '2013-04-02T00:00:00Z'\n",
    "time_end = '2019-07-19T23:59:59Z'\n",
    "output_res = 1000 #desired spatial resoultion in meters (m)\n",
    "directory = \"Raw_ASO_Data\"\n",
    "basinname = 'Tuolumne'\n",
    "\n",
    "#Get ASO data\n",
    "folder_name = f\"files/ASO/{basinname}/{directory}\"\n",
    "data_tool = ASOget.ASODownload(short_name, version)\n",
    "b_box = data_tool.BoundingBox(basin)  \n",
    "url_list = data_tool.cmr_search(time_start, time_end, basin, b_box)\n",
    "data_tool.cmr_download(folder_name, basinname)\n",
    "\n",
    "#Convert ASO tifs to parquet\n",
    "data_processor = ASOget.ASODataProcessing()\n",
    "data_processor.convert_tiff_to_parquet_multiprocess(directory, output_res, basinname) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code to unzip the preprosed ASO images and continue the hydrolearn activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_res = 1000 #desired spatial resoultion in meters (m)\n",
    "basinname = 'Tuolumne'\n",
    "\n",
    "# Path to the zip file\n",
    "zip_file_path = f\"files/ASO/{basinname}/{output_res}M_SWE_parquet.zip\"\n",
    "\n",
    "\n",
    "# Path to the directory where you want to extract the files\n",
    "extract_to_path = f\"files/ASO/{basinname}/{output_res}M_SWE_parquet/\"\n",
    "\n",
    "# Ensure the extraction directory exists\n",
    "os.makedirs(extract_to_path, exist_ok=True)\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_path)\n",
    "\n",
    "print(f\"Files have been extracted to {extract_to_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = 'seismic' # use seismic for error, viridis or blues for preds/obs\n",
    "var =  'swe_in' #'error'\n",
    "savfig = True\n",
    "variant = 'World_Imagery'\n",
    "markersize = 60\n",
    "swethres = 0.1\n",
    "plttitle = 'N/A'\n",
    "\n",
    "#Get all file names for ASO images in Tuolumne river basin\n",
    "files = [f for f in os.listdir(f\"files/ASO/{basinname}/{output_res}M_SWE_parquet/\") if os.path.isfile(os.path.join(f\"files/ASO/{basinname}/{output_res}M_SWE_parquet/\", f))]\n",
    "files = [files[0]]\n",
    "\n",
    "SSWEET.SpatialAnalysis(files, basinname, output_res, markersize, cmap, var,variant,swethres,plttitle, pltfig = True, savfig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate spatiotemporal average SWE values\n",
    "\n",
    "Apply methods to determine the patial mean/median SWE for the Tuolumne watershed above hetch hetchy reservoir for a specific time of year (e.g., Peak SWE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basinname = 'Tuolumne'\n",
    "output_res = 1000 #desired spatial resoultion in meters (m)\n",
    " # get files of interest\n",
    "begdate = 325 #march 25th\n",
    "enddate = 407 #april 7th\n",
    "filename = f\"{basinname}_median_SWE_04-01.parquet\"\n",
    "decround = 2\n",
    "\n",
    "MedianSWE_df = dataprocessing.Spatial_median_SWE_df(output_res, basinname, begdate, enddate, filename,decround,  save = True)\n",
    "MedianSWE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot median SWE\n",
    "basinname = 'Tuolumne'\n",
    "output_res = 1000 #desired spatial resoultion in meters (m)\n",
    " # get files of interest\n",
    "filename = [f\"{basinname}_median_SWE_04-01.parquet\"]\n",
    "cmap = 'viridis' # use seismic for error, viridis or blues for preds/obs\n",
    "var =  'median_SWE_in' #'error'\n",
    "savfig = True\n",
    "variant = 'World_Imagery'\n",
    "markersize = 60\n",
    "swethres = 0.1\n",
    "plttitle = 'Median SWE in Tuolumne River Basin on April 1st'\n",
    "\n",
    "SSWEET.SpatialAnalysis(filename, basinname, output_res, markersize, cmap, var,variant,swethres,plttitle, pltfig = True, savfig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Spatially compare a year of interest to the historical swe value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basinname = 'Tuolumne'\n",
    "output_res = 1000 #desired spatial resoultion in meters (m)\n",
    "medianSWEfile = f\"{basinname}_median_SWE_04-01.parquet\"\n",
    "date = '20190324' #date of interest\n",
    "WYSWEfile = f\"ASO_{output_res}M_SWE_{date}.parquet\"\n",
    "swedifffilename = f\"{basinname}_SWEDiff_{date}.parquet\"\n",
    "decround = 2\n",
    "\n",
    "df = dataprocessing.SWE_diff(basinname, output_res, medianSWEfile, WYSWEfile,decround,swedifffilename, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the SWE difference\n",
    "basinname = 'Tuolumne'\n",
    "output_res = 1000 #desired spatial resoultion in meters (m)\n",
    " # get files of interest\n",
    "filename = [swedifffilename]\n",
    "cmap = 'seismic_r' # use seismic for error, viridis or blues for preds/obs\n",
    "var =  'SWE_diff_in' #'error'\n",
    "savfig = True\n",
    "variant = 'World_Imagery'\n",
    "markersize = 60\n",
    "swethres = 0.1\n",
    "plttitle = 'SWE Difference to Median in Tuolumne River Basin on April 1st'\n",
    "\n",
    "SWEdiff = SSWEET.SpatialAnalysis(filename, basinname, output_res, markersize, cmap, var,variant,swethres,plttitle, pltfig = True, savfig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the SWE difference\n",
    "basinname = 'Tuolumne'\n",
    "output_res = 1000 #desired spatial resoultion in meters (m)\n",
    " # get files of interest\n",
    "filename = [swedifffilename]\n",
    "cmap = 'seismic_r' # use seismic for error, viridis or blues for preds/obs\n",
    "var =  'SWE_perc_norm' #SWE_diff_in' #'error',\n",
    "savfig = True\n",
    "variant = 'World_Imagery'\n",
    "markersize = 60\n",
    "swethres = 0.1\n",
    "plttitle = 'SWE Percentage Difference to Median in Tuolumne River Basin on April 1st'\n",
    "\n",
    "SWEdiff = SSWEET.SpatialAnalysis(filename, basinname, output_res, markersize, cmap, var,variant,swethres,plttitle, pltfig = True, savfig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Investigate the differences between median and current basin snow conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get elevation data for each pixel in the basin, this may take a few moments\n",
    "SWEdiff_elev = get_Elevation.extract_terrain_data_threaded(SWEdiff,basinname, output_res)\n",
    "SWEdiff_elev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incols = ['median_SWE_in', \"swe_in\"]\n",
    "#outcols =['Volume_Difference', 'Median_Volume', 'Observed_Volume']\n",
    "outcols =['median_SWE_in', \"swe_in\"]\n",
    "ncol = 3\n",
    "output_res = 1000\n",
    "region = 'Sierra Nevada'\n",
    "\n",
    "Title = f'Volumetric Frozen Water Content at Low, Mid, and High Elevation Bands \\n {basinname} River Basin, {region} {date}'\n",
    "save = True\n",
    "figname = f\"Figures/ASO/{basinname}/{output_res}M/{basinname}_ElevationVol_{date}.png\"\n",
    "\n",
    "Depthdf = SSWEET.barplot(SWEdiff_elev, incols, outcols, output_res, ncol, Title, save, figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incols = ['median_SWE_in', \"swe_in\"]\n",
    "outcols =['Volume_Difference', 'Median_Volume', 'Observed_Volume']\n",
    "region = 'Sierra Nevada'\n",
    "ncol = 3\n",
    "output_res = 1000\n",
    "Title = f'Volumetric Frozen Water Content at Low, Mid, and High Elevation Bands \\n {basinname} River Basin, {region} {date}'\n",
    "save = True\n",
    "figname = f\"Figures/ASO/{basinname}/{output_res}M/{basinname}_ElevationVol_{date}.png\"\n",
    "\n",
    "Vdf = SSWEET.barplot(SWEdiff_elev, incols, outcols, output_res, ncol, Title, save, figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "incols = ['SWE_perc_norm']\n",
    "outcols =['SWE_perc_norm']\n",
    "region = 'Sierra Nevada'\n",
    "ncol = 3\n",
    "output_res = 1000\n",
    "Title = f'Volumetric Frozen Water Content at Low, Mid, and High Elevation Bands \\n {basinname} River Basin, {region} {date}'\n",
    "save = True\n",
    "figname = f\"Figures/ASO/{basinname}/{output_res}M/{basinname}_ElevationPerc_{date}.png\"\n",
    "\n",
    "Percdf = SSWEET.barplot(SWEdiff_elev, incols, outcols, output_res, ncol, Title, save, figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HydroLearnEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
